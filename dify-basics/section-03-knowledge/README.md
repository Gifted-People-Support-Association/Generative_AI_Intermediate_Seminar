# 第3回：知識ブロックと外部ナレッジベース

## この回で学ぶこと

- ナレッジベースの本質と仕組み
- RAG（Retrieval-Augmented Generation）の理解
- Difyでの知識ベース作成と管理
- 知識検索ノードの使い方
- 外部知識ソースの活用方法
- 会話履歴の管理とRAGの統合
- マーケットプレイスの組み込みツール

**前提知識：** 第2回までの内容（LLMノードとプロンプト設計）を理解していることが望ましいです。

---

## 目次

1. [ナレッジベースとは](#1-ナレッジベースとは)
2. [RAGの仕組み](#2-ragの仕組み)
3. [Difyでの知識ベース作成](#3-difyでの知識ベース作成)
4. [知識検索ノードの使い方](#4-知識検索ノードの使い方)
5. [実践：RAGアプリケーションを作る](#5-実践ragアプリケーションを作る)
6. [外部ナレッジベースの活用](#6-外部ナレッジベースの活用)
   - 6.5. [会話履歴とRAGの統合](#65-会話履歴とragの統合)
7. [マーケットプレイスの組み込みツール](#7-マーケットプレイスの組み込みツール)

---

## 1. ナレッジベースとは
ナレッジベースとは、組織や個人の知識・経験・ノウハウを、誰でも・いつでも・簡単に活用できるように整理・蓄積した『情報の宝庫』のことです。

### 日常でこんな困りごとはありませんか？

**ケース1: 新入社員の質問対応**
```
新入社員「有給休暇の申請方法を教えてください」
あなた「えっと、確か社内Wikiのどこかに...（15分探す）」
```

**ケース2: カスタマーサポート**
```
お客様「この製品の保証期間は？」
担当者「少々お待ちください...（マニュアルをめくる）」
```

**ケース3: 個人の知識管理**
```
あなた「あのレシピ、どこにメモしたっけ？」
（ノート、メモアプリ、ブックマーク...あちこち探す）
```

これらの問題、実は**ナレッジベース**で解決できます。

### ナレッジベースで何ができるのか？

**ナレッジベース**を使うと、以下のようなことが実現できます：

#### 🎯 企業での活用例

**1. 24時間対応のカスタマーサポートボット**
```
お客様「製品の初期設定方法は？」
  ↓
AIボット「製品マニュアルから検索...」
  ↓
「以下の手順で設定できます：
 1. 電源ケーブルを接続
 2. 初期設定画面で言語を選択
 3. Wi-Fi設定を完了

 （参照：製品マニュアル p.12）」
```

**効果：**
- ✅ 深夜や休日でも即座に回答
- ✅ 人間のオペレーターは複雑な問い合わせに集中
- ✅ 回答の品質が一定（ベテランも新人も同じ回答）

**2. 社内ヘルプデスク**
```
社員「経費精算のルールを教えて」
  ↓
社内AIアシスタント「経費規定から検索...」
  ↓
「領収書は必ず原本を提出してください。
 申請期限は月末から1週間以内です。

 （参照：経費精算規定 第3条）」
```

**効果：**
- ✅ 総務部への問い合わせが減る
- ✅ 社員は待たずに回答を得られる
- ✅ 最新の規定が常に反映される

**3. 技術サポート**
```
エンジニア「このエラーの解決方法は？」
  ↓
技術AIアシスタント「過去の障害事例から検索...」
  ↓
「似たエラーが2023年11月に発生しています。
 原因：データベース接続タイムアウト
 解決：接続プールのサイズを50→100に変更

 （参照：障害報告書 #2023-1145）」
```

**効果：**
- ✅ 過去の知見を即座に活用
- ✅ 同じ問題の再発を防ぐ
- ✅ 新人エンジニアでもベテランの知識にアクセス

#### 🏠 個人での活用例

**1. パーソナル料理アシスタント**
```
あなた「冷蔵庫にある鶏肉と玉ねぎで作れる料理は？」
  ↓
AIアシスタント「保存したレシピから検索...」
  ↓
「チキンカレーがおすすめです！
 以前作って美味しかったと記録されています。

 （参照：2023年5月のレシピメモ）」
```

**2. 学習アシスタント**
```
あなた「ReactのuseEffectの使い方は？」
  ↓
学習AIアシスタント「学習ノートから検索...」
  ↓
「以前学習した内容です：
 useEffectは副作用を扱うフックで...
 クリーンアップ関数を返すことで...

 （参照：2024年3月の学習ノート）」
```

**3. 旅行計画アシスタント**
```
あなた「京都でおすすめのカフェは？」
  ↓
AIアシスタント「過去の旅行記録から検索...」
  ↓
「2022年の京都旅行で訪れた「○○カフェ」が
 とても良かったとメモされています。

 （参照：2022年京都旅行記）」
```

### なぜナレッジベースが必要なのか？

LLMだけでは、以下の問題があります：

#### 問題1: 知識の鮮度 📅

**LLMの限界：**
```
あなた「2024年の最新の税制改正について教えて」
ChatGPT「私の学習データは2023年4月までです。
        2024年の情報は持っていません」
```

**ナレッジベースなら：**
```
あなた「2024年の最新の税制改正について教えて」
AIアシスタント「税理士事務所のサイトから最新情報を取得...」
  ↓
「2024年度は住宅ローン控除の要件が変更され...
 （参照：国税庁の最新PDF）」
```

#### 問題2: 専門知識の不足 🏢

**LLMの限界：**
```
新入社員「我が社の勤怠システムの使い方は？」
ChatGPT「一般的な勤怠システムの説明はできますが、
        御社独自のシステムについては分かりません」
```

**ナレッジベースなら：**
```
新入社員「我が社の勤怠システムの使い方は？」
社内AIアシスタント「社内マニュアルから検索...」
  ↓
「当社の勤怠システム『SmartTime』の使い方：
 1. 社員IDでログイン
 2. 出勤ボタンをタップ
 3. 退勤時も同様に...

 （参照：新人研修マニュアル p.25）」
```

#### 問題3: ハルシネーション（幻覚）🌀

**LLMの限界：**
```
あなた「〇〇製品の型番ABC-123の仕様は？」
ChatGPT「ABC-123は以下の仕様です：
        - サイズ：30cm × 20cm
        - 重量：500g
        ...」
（実際には存在しない製品だが、もっともらしく答える）
```

**ナレッジベースなら：**
```
あなた「〇〇製品の型番ABC-123の仕様は？」
AIアシスタント「製品データベースから検索...」
  ↓
「申し訳ございません。型番ABC-123は
 データベースに見つかりませんでした。

 類似する型番：ABC-124, ABC-122」
（根拠のない回答はしない）
```

### どう実現するのか？ナレッジベースの仕組み

**ナレッジベース（知識ベース）** とは、LLMが推論・生成時に参照するための、**整理・保存・検索可能な外部知識の集合**です。

```
[外部知識] → [整理・保存] → [検索可能な状態] → [LLMが参照] → [正確な回答]
```

#### 重要な理解：RAGは手段であって本質ではない

多くの人が「ナレッジベース = RAG」と考えがちですが、これは正確ではありません。

**ナレッジベースの本質：**
- LLMが利用できる外部知識の集合
- 信頼できる情報源
- 検索・取得可能な構造化された知識

**RAGの役割：**
- ナレッジベースから知識を**取得する手段の一つ**
- ベクトル検索を使った効率的な情報検索方法

#### 外部知識を取得する様々な方法

ナレッジベースへのアクセス方法は、RAGだけではありません：

| 方法 | 説明 | 使いどころ | 実例 |
|------|------|-----------|------|
| **RAG（ベクトル検索）** | 文章を埋め込みベクトルに変換して類似検索 | ドキュメント、FAQ、マニュアル | 製品マニュアル検索、社内規定検索 |
| **カスタムツール** | 独自のAPIやデータベースから情報取得 | 在庫情報、顧客データ、リアルタイムデータ | ECサイトの在庫照会、顧客履歴検索 |
| **MCPツール** | Model Context Protocolを使った統合 | Notion、Google Drive、外部システム | Notionの議事録検索、Googleドライブのファイル取得 |
| **Webスクレイピング** | Webサイトから最新情報を取得 | ニュース、価格情報、公開データ | 最新ニュース取得、競合価格調査 |
| **データベースクエリ** | SQLなどで直接データベースにアクセス | 商品情報、取引履歴 | 売上データ分析、顧客情報照会 |

### ナレッジベースを使うメリット

✅ **正確性の向上**
- 信頼できる情報源から回答を生成
- 根拠のある回答（ソース付き）
- ハルシネーション（幻覚）の大幅な削減

✅ **最新情報の活用**
- リアルタイムで更新される情報にアクセス
- ドキュメントを更新すれば即座に反映
- 常に最新の知識を提供

✅ **専門性の実現**
- 企業独自の知識を活用
- カスタマイズされた回答
- 自社のルールや文化に沿った対応

✅ **業務効率化**
- 問い合わせ対応時間の削減
- 人的リソースの最適化
- 24時間365日対応可能

### まとめ：ナレッジベースの本質

ナレッジベースは、**「AIに正しい知識を使って答えてもらうための仕組み」**です。

```
【従来】
AI単体 → 一般的な知識のみ → 不正確な回答の可能性

【ナレッジベース活用】
AI + 専門知識 → 根拠のある正確な回答 → 信頼性の高いサービス
```

次のセクションでは、この仕組みを実現する代表的な技術「RAG（検索拡張生成）」について詳しく学びます。

---

## 2. RAGの仕組み

### RAGとは

**RAG（Retrieval-Augmented Generation：検索拡張生成）** は、外部知識検索と言語生成を組み合わせた技術です。

### RAGの3つのステップ

```
ステップ1: インデキシング（事前準備）
[文書] → [分割（チャンク化）] → [埋め込み変換] → [ベクトルDB保存]

ステップ2: 検索（Retrieval）
[ユーザーの質問] → [埋め込み変換] → [類似検索] → [関連文書取得]

ステップ3: 生成（Generation）
[関連文書] + [質問] → [LLM] → [根拠のある回答]
```

### ステップ1: インデキシング（事前準備）

文書を検索可能な形に変換します。

#### 1-1. チャンク化（文書の分割）

長い文書を小さな単位（チャンク）に分割します。

**なぜ分割するのか：**
- LLMには入力できる文字数に制限がある
- 関連する部分だけを効率的に取得するため

**チャンクの例：**
```
【元の文書】（1000文字の製品マニュアル）

↓ チャンク化

【チャンク1】（200文字）
製品の概要と特徴について...

【チャンク2】（200文字）
セットアップ手順について...

【チャンク3】（200文字）
トラブルシューティングについて...
```

**チャンクサイズの設定：**

| サイズ | 目安 | 使いどころ |
|--------|------|-----------|
| **小さい（100-200トークン）** | 1-2段落 | 短い質問、キーワード検索 |
| **中程度（300-500トークン）** | 数段落 | 一般的なドキュメント |
| **大きい（800-1000トークン）** | 複数段落、長文 | 詳細な説明が必要な場合 |

#### 1-2. 埋め込み変換（Embedding）

テキストを数値ベクトルに変換します。

**埋め込みとは：**
```
テキスト「猫は可愛い動物です」
↓ 埋め込みモデル
ベクトル [0.2, -0.5, 0.8, 0.1, ...]（1536次元など）
```

**埋め込みの性質：**
- 意味が似た文章は、ベクトル空間で近い位置になる
- 「犬は可愛い」と「猫は可愛い」は近い
- 「猫は可愛い」と「数学の公式」は遠い

**主要な埋め込みモデル：**

| モデル | 提供元 | 次元数 | 特徴 |
|--------|--------|--------|------|
| **text-embedding-ada-002** | OpenAI | 1536 | 高性能、英語に強い |
| **text-embedding-3-small** | OpenAI | 1536 | コスト効率が良い |
| **text-embedding-3-large** | OpenAI | 3072 | 最高性能 |
| **embedding-001** | Google | 768 | 多言語対応 |

#### 1-3. ベクトルデータベース保存

生成されたベクトルを専用のデータベースに保存します。

**ベクトルデータベースの役割：**
- 高速な類似検索
- 大量のベクトルを効率的に管理

**主要なベクトルDB：**
- **Pinecone** - クラウド型、簡単に使える
- **Weaviate** - オープンソース、多機能
- **Qdrant** - 高速、Rust製
- **Dify内蔵DB** - Difyに組み込み済み

### ステップ2: 検索（Retrieval）

ユーザーの質問から関連する文書を取得します。

#### 2-1. 質問の埋め込み変換

```
ユーザーの質問「製品のセットアップ方法は?」
↓ 同じ埋め込みモデル
ベクトル [0.3, -0.4, 0.7, 0.2, ...]
```

#### 2-2. 類似検索

ベクトルデータベースで、質問に近いチャンクを探します。

**検索パラメータ：**

**Top K（上位K件）**
- 取得する文書の数
- 例：Top K = 3 → 最も関連度が高い3件を取得

**スコア閾値（Score Threshold）**
- 関連度の最低基準（0〜1）
- 例：0.7以上のもののみ取得

```
質問ベクトル vs データベース内のベクトル
↓ コサイン類似度計算
スコア: 0.95（チャンク2：セットアップ手順） ← 最も関連
スコア: 0.72（チャンク1：製品概要）
スコア: 0.45（チャンク3：トラブルシューティング）

→ Top K=2, 閾値=0.7 の場合
  → チャンク2とチャンク1を取得
```

### ステップ3: 生成（Generation）

取得した文書を使ってLLMが回答を生成します。

#### プロンプトの構成

```
【システムプロンプト】
あなたは親切なアシスタントです。
以下の情報を参考に、ユーザーの質問に答えてください。

【参考情報】（検索で取得した文書）
---
チャンク2（スコア: 0.95）
セットアップ手順：
1. 電源ケーブルを接続
2. 初期設定画面で言語を選択
3. Wi-Fi設定を完了
---
チャンク1（スコア: 0.72）
本製品は...
---

【ユーザーの質問】
製品のセットアップ方法は?

【回答】
```

**LLMの出力：**
```
製品のセットアップは以下の手順で行います：

1. 電源ケーブルを本体に接続してください
2. 初期設定画面が表示されたら、使用する言語を選択します
3. Wi-Fi設定を完了させてください

これでセットアップは完了です。
```

### RAGのメリットとデメリット

#### メリット

✅ **正確性の向上**
- 実際の文書に基づいた回答
- ハルシネーションの減少

✅ **ソースの提示**
- どの文書から情報を得たか明示
- 信頼性の向上

✅ **知識の更新が容易**
- 文書を追加・更新すれば即座に反映
- モデルの再学習不要

#### デメリット

❌ **初期設定のコスト**
- 文書の準備とインデキシング
- 埋め込みモデルの選定

❌ **検索精度の課題**
- 関連する文書が見つからない場合がある
- チャンクサイズの調整が必要

❌ **処理時間**
- 検索 + 生成で通常のLLMより遅い

---

## 3. Difyでの知識ベース作成

### ステップ1: 知識ベースの作成

1. Difyにログイン
2. 左メニューから「ナレッジ」をクリック
3. 「ナレッジベースを作成」ボタンをクリック
4. 以下を設定：
   - **名前**：わかりやすい名前（例：「製品マニュアル」）
   - **説明**：このナレッジベースの用途
   - **権限**：「自分のみ」または「チーム全体」

### ステップ2: ドキュメントのアップロード

Difyは様々な形式のドキュメントをサポートしています。

#### 対応ファイル形式

| カテゴリ | 形式 |
|---------|------|
| **文書** | TXT, MD, PDF, DOCX |
| **表計算** | CSV, XLSX |
| **コード** | HTML, JSON, XML |
| **その他** | Markdown, RTF |

#### アップロード方法

**方法1: ファイルアップロード**

1. 「ドキュメントを追加」をクリック
2. 「ファイルをアップロード」を選択
3. ファイルを選択またはドラッグ&ドロップ
4. アップロード完了を待つ

**方法2: テキスト入力**

1. 「ドキュメントを追加」をクリック
2. 「テキストを入力」を選択
3. ドキュメント名とテキストを入力
4. 保存

**方法3: Webサイトから取得**

1. 「ドキュメントを追加」をクリック
2. 「Webページから同期」を選択
3. URLを入力
4. 取得設定を選択（単一ページ or サイト全体）

**方法4: Notion連携**

1. 「ドキュメントを追加」をクリック
2. 「Notionから同期」を選択
3. Notionアカウントと連携
4. 取り込むページを選択

### ステップ3: チャンク化設定

アップロード後、ドキュメントをどのように分割するか設定します。

#### 自動モード（推奨）

Difyが自動的に最適な分割を行います。

**設定項目：**
- **チャンクサイズ**：500トークン（デフォルト）
- **チャンク重複**：50トークン（前後のチャンクとの重複）

**重複（Overlap）とは：**
```
【チャンク1】
...文脈が途切れないように、次の章では...

【チャンク2】（50トークン重複）
...次の章では詳しく説明します...
```
→ 文脈が繋がり、検索精度が向上

#### カスタムモード（上級者向け）

細かく設定をカスタマイズできます。

**設定項目：**

1. **前処理ルール**
   - 余分な空白を削除
   - URLとメールアドレスを削除
   - 特殊文字の処理

2. **セグメント設定**
   - **区切り文字**：`\n\n`（段落区切り）、`###`（見出し）など
   - **最大トークン数**：各チャンクの最大サイズ
   - **チャンク重複**：重複するトークン数

3. **前処理オプション**
   - **余分な改行を削除**：`はい`（推奨）
   - **URLを削除**：`はい`（ドキュメントによる）

**推奨設定例：**

```
【一般的なドキュメント】
- チャンクサイズ：500トークン
- 重複：50トークン
- 区切り文字：\n\n（段落区切り）

【FAQ形式】
- チャンクサイズ：300トークン
- 重複：30トークン
- 区切り文字：Q&A単位で区切る

【技術マニュアル】
- チャンクサイズ：800トークン
- 重複：100トークン
- 区切り文字：###（見出し区切り）
```

### ステップ4: 埋め込みモデルの選択

**デフォルト設定：**
- Difyが推奨するモデルを自動選択
- 多くの場合、これで十分

**カスタム設定：**
1. 設定アイコンをクリック
2. 「埋め込みモデル」を選択
3. モデルとプロバイダを選択

**モデル選択のポイント：**

| 用途 | 推奨モデル |
|------|-----------|
| **英語中心** | text-embedding-3-small |
| **日本語中心** | multilingual-e5-large-instruct |
| **高精度重視** | text-embedding-3-large |
| **コスト重視** | text-embedding-ada-002 |

### ステップ5: インデキシング開始

1. 設定を確認
2. 「保存してインデキシング」をクリック
3. インデキシング処理が開始されます

**進行状況の確認：**
- ドキュメントリストで進行状況を確認
- ステータス：「処理中」→「完了」
- エラーがある場合はエラーメッセージを確認

---

## 4. 知識検索ノードの使い方

### 知識検索ノードとは

**知識検索ノード（Knowledge Retrieval Node）** は、ワークフロー内でナレッジベースを検索するためのノードです。

```
[開始ノード] → [知識検索ノード] → [LLMノード] → [終了ノード]
     ↓              ↓                  ↓
  ユーザー質問   関連文書を検索    文書を参考に回答生成
```

### ノードの追加と設定

#### ステップ1: ノードの追加

1. ワークフローキャンバスで「＋」をクリック
2. 「知識検索」ノードを選択
3. ノードが追加されます

#### ステップ2: ナレッジベースの選択

1. 追加した知識検索ノードをクリック
2. 右パネルで「ナレッジベース」を選択
3. 事前に作成したナレッジベースを選択

#### ステップ3: クエリ変数の設定

検索に使用する質問文を指定します。

**通常の設定：**
```
クエリ変数：{{#start.question#}}
```
→ ユーザーの質問をそのまま検索

**LLMで質問を最適化する場合：**
```
[開始ノード] → [LLMノード：質問最適化] → [知識検索ノード]
```

LLMノード（質問最適化）のプロンプト例：
```
ユーザーの質問を、知識ベース検索に最適な形に変換してください。

【ユーザーの質問】
{{#start.user_question#}}

【最適化のポイント】
- キーワードを明確にする
- 曖昧な表現を具体化する
- 検索しやすい形式にする

【最適化された質問】
```

#### ステップ4: 検索パラメータの設定

**Top K（取得件数）**

| 設定値 | 説明 | 使いどころ |
|--------|------|-----------|
| **1-2件** | 最も関連度の高い情報のみ | 簡潔な回答、FAQ |
| **3-5件** | 標準的な設定 | 一般的なドキュメント検索 |
| **10件以上** | 幅広く情報を収集 | 複雑な質問、詳細な回答 |

**スコア閾値（Score Threshold）**

関連度の最低基準を設定します（0.0〜1.0）。

| 設定値 | 説明 |
|--------|------|
| **0.7以上** | 高い関連性のみ（厳密） |
| **0.5-0.7** | 標準的な関連性 |
| **0.5未満** | 緩い基準（広範囲に取得） |

**リランキング（Reranking）**

検索結果を再度スコアリングして精度を向上させます。

- **有効化**：より正確な結果
- **無効化**：高速だが精度は標準

**おすすめ設定：**
```
Top K: 3
スコア閾値: 0.7
リランキング: 有効
```

### ノードの出力

知識検索ノードは以下の情報を出力します：

**出力変数：**

| 変数名 | 内容 |
|--------|------|
| **result** | 検索結果のテキスト（結合済み） |
| **records** | 検索結果の配列（個別のチャンク） |

**LLMノードでの使用例：**

```
以下の情報を参考に、ユーザーの質問に答えてください。

【参考情報】
{{#知識検索ノード.result#}}

【質問】
{{#start.question#}}

【回答】
```

---

## 5. 実践：RAGアプリケーションを作る

### 演習1: 製品FAQボット

**目標：** 製品マニュアルを使った質問応答ボット

#### 手順

**1. ナレッジベースの準備**

サンプルFAQテキスト：
```
Q: 製品の保証期間はどれくらいですか？
A: 本製品は購入日から1年間の保証が付いています。

Q: 初期不良の場合はどうすればいいですか？
A: 購入後7日以内であれば、無償で交換いたします。

Q: 修理にかかる費用は？
A: 保証期間内は無料です。保証期間外は部品代と作業料が発生します。

Q: 製品のセットアップ方法は？
A: 1. 電源ケーブルを接続 2. 初期設定画面で言語を選択 3. Wi-Fi設定を完了

Q: パスワードを忘れた場合は？
A: 設定画面から「パスワードをリセット」を選択してください。
```

1. ナレッジベースを作成（名前：「製品FAQ」）
2. 上記テキストを「テキスト入力」で追加
3. チャンク設定：
   - チャンクサイズ：300トークン
   - 重複：30トークン

**2. ワークフローの構築**

```
[開始ノード]
  ↓ 入力変数：question（ユーザーの質問）
[知識検索ノード]
  ↓ ナレッジベース：製品FAQ
  ↓ Top K: 3
  ↓ スコア閾値: 0.7
[LLMノード]
  ↓
[終了ノード]
```

**3. LLMノードのプロンプト**

```
あなたは製品サポート担当者です。
FAQを参考に、ユーザーの質問に丁寧に答えてください。

【FAQ情報】
{{#知識検索ノード.result#}}

【お客様からの質問】
{{#start.question#}}

【回答のルール】
- FAQに記載されている情報を正確に伝える
- 丁寧で親切な言葉遣いを使う
- FAQに情報がない場合は「申し訳ございません、その情報はFAQに記載がございません」と伝える

【回答】
```

**4. テスト実行**

質問例：
- 「保証期間は何年ですか？」
- 「パスワードを忘れてしまいました」
- 「セットアップの手順を教えてください」

### 演習2: 社内文書検索システム

**目標：** 複数の社内文書から情報を検索

#### シナリオ

以下の3つの文書を管理：
1. 就業規則
2. 有給休暇の取り方
3. 経費精算マニュアル

#### ワークフロー構成

```
[開始ノード]
  ↓
[LLMノード1：質問の分類]（構造化出力）
  ↓
[条件分岐ノード]
  ├─ カテゴリ「就業規則」 → [知識検索ノード1：就業規則DB]
  ├─ カテゴリ「休暇」 → [知識検索ノード2：休暇DB]
  └─ カテゴリ「経費」 → [知識検索ノード3:経費DB]
  ↓
[LLMノード2：回答生成]
  ↓
[終了ノード]
```

**LLMノード1のJSON Schema：**

```json
{
  "type": "object",
  "properties": {
    "category": {
      "type": "string",
      "description": "質問のカテゴリ",
      "enum": ["就業規則", "休暇", "経費", "その他"]
    },
    "optimized_query": {
      "type": "string",
      "description": "検索に最適化された質問文"
    }
  },
  "required": ["category", "optimized_query"]
}
```

**LLMノード1のプロンプト：**

```
ユーザーの質問を分析し、適切なカテゴリに分類してください。

【質問】
{{#start.question#}}

【カテゴリ】
- 就業規則：勤務時間、服装規定、行動規範など
- 休暇：有給休暇、特別休暇、休暇申請など
- 経費：経費精算、出張費、領収書など
- その他：上記に当てはまらない質問

また、質問を検索しやすい形に最適化してください。
```

### 演習3: 引用元を表示するRAGシステム

**目標：** 回答に引用元（ソース）を明示

#### ワークフロー構成

```
[開始ノード]
  ↓
[知識検索ノード]
  ↓ records（個別チャンクの配列）を使用
[LLMノード]
  ↓
[終了ノード]
```

**LLMノードのプロンプト：**

```
以下の文書を参考に、ユーザーの質問に答えてください。
回答の最後に、参考にした文書のタイトルとスコアを記載してください。

【参考文書】
{{#知識検索ノード.result#}}

【質問】
{{#start.question#}}

【回答形式】
（回答内容）

---
参考文書：
- 文書名1（関連度: XX%）
- 文書名2（関連度: XX%）
```

**ポイント：**
- `{{#知識検索ノード.result#}}`には検索結果のテキストが含まれます
- プロンプトでLLMに引用元の表示形式を指示することで、ソース情報を明示できます
- より詳細なメタデータが必要な場合は、知識ベース作成時にドキュメントにタイトルや説明を設定しておきましょう

---

## 6. 外部ナレッジベースの活用

### 外部ナレッジベースとは

**外部ナレッジベース（External Knowledge Base）** は、Difyの外部で管理されている独自のナレッジベースと連携する機能です。

### 使用するケース

| ケース | 説明 |
|--------|------|
| **既存システムとの統合** | すでに運用中の検索システムを活用 |
| **独自のベクトルDB** | Pinecone、Weaviateなど専用DBを使用 |
| **リアルタイム更新** | 常に最新データを取得したい場合 |
| **高度なフィルタリング** | メタデータによる複雑な検索条件 |

### 外部ナレッジベースAPI仕様

DifyはREST APIで外部ナレッジベースと通信します。

#### エンドポイント

```
POST <your-endpoint>/retrieval
```

#### リクエスト形式

```json
{
  "knowledge_id": "your-knowledge-id",
  "query": "ユーザーの質問",
  "retrieval_setting": {
    "top_k": 3,
    "score_threshold": 0.7
  }
}
```

#### レスポンス形式

```json
{
  "records": [
    {
      "content": "これは外部知識の文書です。",
      "score": 0.98,
      "title": "knowledge.txt",
      "metadata": {
        "path": "s3://dify/knowledge.txt",
        "description": "dify 知識文書"
      }
    },
    {
      "content": "GenAI アプリケーションの創新エンジン",
      "score": 0.66,
      "title": "introduce.txt",
      "metadata": {
        "path": "s3://dify/introduce.txt",
        "description": "dify 紹介"
      }
    }
  ]
}
```

### Difyでの設定

1. ナレッジベース作成画面で「外部ナレッジベース」を選択
2. 以下を設定：
   - **エンドポイントURL**：`https://your-api.com/retrieval`
   - **APIキー**：認証用のキー
   - **Knowledge ID**：知識ベースの識別子

---

## 6.5 会話履歴とRAGの統合

### なぜ会話履歴とRAGの統合が重要なのか？

RAGを使えば正確な情報を提供できますが、**会話の文脈を覚えていない**という課題があります。

**よくある問題：**

```
ユーザー「FlowMasterの料金プランを教えて」
AIボット「Freeプランは無料、Proプランは月額1,200円、Enterpriseプランはお問い合わせです」

ユーザー「Proプランの詳細は？」
AIボット「申し訳ございません。どのプランについてお知りになりたいですか？」
  ↓
（直前に「Proプラン」と言ったのに忘れている！）
```

**会話履歴とRAGを組み合わせれば：**

```
ユーザー「FlowMasterの料金プランを教えて」
AIボット「Freeプランは無料、Proプランは月額1,200円、Enterpriseプランはお問い合わせです」
  ↓ 会話履歴に保存

ユーザー「Proプランの詳細は？」
AIボット「先ほどご案内したProプランですね。以下の機能が含まれます...」
  ↓ RAG検索 + 会話履歴参照
（文脈を理解した自然な回答！）
```

このセクションでは、会話履歴を管理しながらRAGを活用する方法を学びます。

---

### 会話履歴の重要性

#### 短期記憶と長期記憶

人間の記憶と同じように、AIにも2種類の記憶があります。

**短期記憶（直近の会話）**

```
【例：レストラン予約ボット】
ユーザー「明日の夜7時に2名で予約したい」
ボット「かしこまりました。明日の19時、2名様ですね」

ユーザー「窓側の席がいいです」
ボット「窓側の席をご用意いたします」
  ↓
短期記憶：「明日19時、2名、窓側」を覚えている
```

**長期記憶（過去の情報）**

```
【例：カスタマーサポート】
ユーザー「先月問い合わせた商品について教えて」
  ↓
長期記憶：RAGで過去の問い合わせ履歴から検索
  ↓
ボット「先月ご質問いただいた商品ABC-123についてですね。
      その後、以下の改善を行いました...」
```

| 記憶の種類 | 保存場所 | 保存期間 | 使いどころ |
|----------|---------|---------|-----------|
| **短期記憶** | LLMのコンテキスト、会話変数 | 会話セッション中 | 直近の文脈理解 |
| **長期記憶** | RAG（ナレッジベース） | 永続的 | 過去の情報検索 |

#### コンテキストウィンドウの制限

LLMには「コンテキストウィンドウ」という、一度に処理できる情報量の制限があります。

**主要なLLMのコンテキストウィンドウ：**

| モデル | コンテキストウィンドウ | 日本語で何文字？ | 会話何ターン分？ |
|--------|---------------------|---------------|----------------|
| **GPT-3.5** | 4,096トークン | 約6,000文字 | 約10-15ターン |
| **GPT-4** | 8,192トークン | 約12,000文字 | 約20-30ターン |
| **GPT-4 Turbo** | 128,000トークン | 約192,000文字 | 約300-400ターン |
| **Claude 3** | 200,000トークン | 約300,000文字 | 約500-600ターン |

**問題：コンテキストウィンドウを超えると...**

```
【会話が長くなると】
ターン1: 「私は田中太郎です」
ターン2-50: （様々な会話）
ターン51: 「私の名前は？」
AIボット: 「申し訳ございません。お名前を教えていただけますか？」
  ↓
（最初の情報がコンテキストから外れて忘れられた！）
```

**コスト増加の問題：**

- コンテキストが長いほど、APIコストが増加
- 例：GPT-4で10,000トークン = 約30円/リクエスト
- 会話が100ターン続くと、1回の質問で高額に

#### 実際の課題

**ケース1: 長い会話での情報の喪失**

```
【会議議事録検索ボット】
ユーザー「先週の会議の議事録を見せて」
ボット（RAG検索）「こちらが先週の議事録です...」
  ↓
（30ターンの会話）
  ↓
ユーザー「最初に見せてくれた議事録の2ページ目は？」
ボット「申し訳ございません。どの議事録でしょうか？」
  ↓
（コンテキストから外れて忘れてしまった）
```

**ケース2: 繰り返し質問への非効率な対応**

```
【製品サポートボット】
ユーザー「FlowMasterのセットアップ方法は？」
ボット（RAG検索）「以下の手順でセットアップできます...」

（翌日、同じユーザー）
ユーザー「昨日聞いたセットアップ、もう一度教えて」
ボット（RAG検索）「以下の手順でセットアップできます...」
  ↓
（過去に同じ質問をしたことを知らない → 学習できない）
```

**ケース3: ユーザー情報を踏まえた回答の難しさ**

```
【学習アシスタント】
ユーザー「Pythonの基礎を学びたい」
ボット「Pythonの基礎講座をご案内します...」

ユーザー「次は何を学ぶべき？」
ボット「何を学習されたいですか？」
  ↓
（ユーザーが「Python基礎を学習済み」という情報を保持していない）
```

---

### Difyでの会話履歴管理方法

Difyでは3つの方法で会話履歴を管理できます。

#### Method 1: LLM Memory機能

最もシンプルな方法です。Difyが自動的に会話履歴を管理してくれます。

**仕組み：**

```
【ターン1】
ユーザー「こんにちは」
  ↓
[LLM] → 「こんにちは！」
  ↓ 保存
[Memory: ターン1を記憶]

【ターン2】
ユーザー「私の名前は田中です」
  ↓
[LLM] + [Memory: ターン1] → 「田中さん、よろしくお願いします！」
  ↓ 保存
[Memory: ターン1-2を記憶]

【ターン3】
ユーザー「私の名前は？」
  ↓
[LLM] + [Memory: ターン1-3] → 「田中さんですね」
```

**メリット：**

- ✅ 設定が簡単（自動で有効）
- ✅ 特別な設定不要
- ✅ 自然な会話が可能

**デメリット：**

- ❌ 会話が長くなるとトークン消費が急増
- ❌ コストが高い
- ❌ コンテキストウィンドウの制限を受ける

**使用シーン：**

- 短い会話（5-10ターン程度）
- シンプルなチャットボット
- デモ・プロトタイプ

**Difyでの設定方法：**

1. Chatflowアプリケーションを作成
2. 「機能」→「会話前置記憶」を確認
3. デフォルトで有効（何もしなくてOK）

**Memory機能の内部動作：**

| ターン数 | コンテキストに含まれる内容 | トークン数（概算） | コスト（GPT-4の場合） |
|---------|------------------------|-----------------|-------------------|
| 1-5ターン | 直近5ターン全体 | 500-1,000 | ¥1-2/リクエスト |
| 10ターン | 直近10ターン全体 | 2,000-3,000 | ¥6-9/リクエスト |
| 50ターン | 直近50ターン全体 | 10,000-15,000 | ¥30-45/リクエスト |

#### Method 2: 会話変数（Conversation Variables）

**Dify v0.7.0**で導入された機能で、必要な情報だけを選択的に保存できます。

**出典：** [Dify v0.7.0: Enhancing LLM Memory with Conversation Variables and Variable Assigners](https://dify.ai/blog/enhancing-llm-memory-with-conversation-variables-and-variable-assigners)

**仕組み：**

```
【従来のMemory】
すべての会話を保存 → トークン消費大

【会話変数】
重要な情報だけを変数に保存 → トークン消費小
```

**Variable Assignerノードの使い方：**

```
[開始ノード]
  ↓ ユーザー入力：「私は田中太郎です。Proプランを検討中です」
  ↓
[LLMノード1：情報抽出]
  プロンプト：「以下の文から名前とプランを抽出してください」
  構造化出力：{"name": "田中太郎", "plan": "Pro"}
  ↓
[Variable Assignerノード]
  変数名：user_name
  値：{{#LLMノード1.name#}}

  変数名：interested_plan
  値：{{#LLMノード1.plan#}}
  ↓ 会話変数に保存完了
[LLMノード2：挨拶]
  プロンプト：「{{#conversation.user_name#}}様、{{#conversation.interested_plan#}}プランに
              ご興味をお持ちいただきありがとうございます」
  ↓
[終了ノード]
```

**会話変数の読み書き：**

| 操作 | 構文 | 例 |
|------|------|-----|
| **書き込み** | Variable Assignerノードで設定 | `user_name = "田中太郎"` |
| **読み込み** | `{{#conversation.変数名#}}` | `{{#conversation.user_name#}}` |
| **更新** | 同じ変数名で再度設定 | `user_name = "田中花子"` |
| **削除** | 空文字列を設定 | `user_name = ""` |

**実装例：カスタマーサポートボット**

```
[開始ノード]
  ↓
[条件分岐：初回訪問かチェック]
  ├─ {{#conversation.user_name#}}が空 → [LLMノード：名前を尋ねる]
  │                                    ↓
  │                                  [Variable Assigner：名前を保存]
  └─ {{#conversation.user_name#}}が存在 → [LLMノード：名前で挨拶]
  ↓
[知識検索：FAQ]
  ↓
[LLMノード：回答生成]
  プロンプト：「{{#conversation.user_name#}}様へ：
              {{#知識検索.result#}}」
  ↓
[終了ノード]
```

**Memory機能との違い：**

| 項目 | LLM Memory | 会話変数 |
|------|-----------|---------|
| **保存内容** | 会話履歴全体 | 指定した情報のみ |
| **トークン消費** | 大きい（会話履歴全体） | 小さい（必要な変数のみ） |
| **制御** | 自動 | 手動（明示的に設定） |
| **永続性** | セッション終了で削除 | セッション終了で削除 |
| **コスト** | 高い | 低い |
| **複雑さ** | 簡単 | やや複雑（設計が必要） |

**いつ使うか：**

- ✅ 構造化された情報を管理したい（名前、メール、プランなど）
- ✅ 長い会話でコストを抑えたい
- ✅ 特定の情報だけを保持したい

#### Method 3: conversation_id

API経由でDifyを使う場合の管理方法です。

**出典：** [DifyのAPI経由のチャットボットでもメモリー機能を使う方法](https://note.com/oft0nland/n/n0dd4333ea673)

**仕組み：**

```
【初回リクエスト】
POST /v1/chat-messages
{
  "query": "こんにちは",
  "user": "user-123",
  "conversation_id": ""  ← 空で送る
}

↓ レスポンス
{
  "answer": "こんにちは！",
  "conversation_id": "conv-abc-123"  ← IDが発行される
}

【2回目以降のリクエスト】
POST /v1/chat-messages
{
  "query": "私の名前は田中です",
  "user": "user-123",
  "conversation_id": "conv-abc-123"  ← 前回のIDを使う
}

↓ レスポンス
{
  "answer": "田中さん、よろしくお願いします",
  "conversation_id": "conv-abc-123"
}
```

**セッション管理の実装例（Python）：**

```python
import requests

class DifyClient:
    def __init__(self, api_key):
        self.api_key = api_key
        self.base_url = "https://api.dify.ai/v1"
        self.conversation_id = None  # セッションIDを保持

    def chat(self, message):
        url = f"{self.base_url}/chat-messages"
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        data = {
            "query": message,
            "user": "user-001",
            "conversation_id": self.conversation_id or "",  # 初回は空文字列
            "response_mode": "blocking"
        }

        response = requests.post(url, headers=headers, json=data)
        result = response.json()

        # IDを保存（次回使用）
        self.conversation_id = result.get("conversation_id")

        return result.get("answer")

# 使用例
client = DifyClient(api_key="your-api-key")

# 初回（conversation_id なし）
response1 = client.chat("こんにちは")
print(response1)  # 「こんにちは！」

# 2回目（conversation_id あり）
response2 = client.chat("私の名前は田中です")
print(response2)  # 「田中さん、よろしくお願いします！」

# 3回目（同じconversation_id）
response3 = client.chat("私の名前は？")
print(response3)  # 「田中さんですね」
```

**使用シーン：**

- 外部アプリケーションとの統合
- Webアプリ、モバイルアプリから利用
- セッション管理を自分で実装したい場合

#### 3つの方法の比較と使い分け

| 方法 | トークン消費 | 実装難易度 | コスト | 使用シーン |
|------|------------|----------|--------|-----------|
| **LLM Memory** | 大 | ★☆☆（簡単） | 高 | 短い会話、デモ |
| **会話変数** | 小 | ★★☆（中） | 低 | 長い会話、構造化データ |
| **conversation_id** | 中 | ★★★（やや難） | 中 | API統合、外部アプリ |

**推奨アプローチ：**

```
【シンプルなチャットボット（5-10ターン）】
→ LLM Memory

【長い会話・カスタマーサポート（20ターン以上）】
→ 会話変数

【外部アプリケーション統合】
→ conversation_id
```

---

### 会話履歴とRAGの組み合わせパターン

会話履歴とRAGを組み合わせることで、**自然な対話** + **正確な情報提供**が実現できます。

#### パターン1: 直近はMemory、古い情報はRAG

**ユースケース：カスタマーサポート**

```
【今日の会話】（Memory）
顧客「商品ABC-123について質問があります」
  ↓ Memoryに保存

顧客「この商品のセットアップ方法は？」
  ↓ Memory: "商品ABC-123"を覚えている
  ↓ RAG: "ABC-123 セットアップ"で検索
  ↓
ボット「ABC-123のセットアップ方法ですね。以下の手順で...」

【過去の問い合わせ】（RAG）
顧客「先月問い合わせた件はどうなりましたか？」
  ↓ RAG: 過去の問い合わせ履歴を検索
  ↓
ボット「先月の〇〇の件ですね。その後、以下の対応を行いました...」
```

**ワークフロー図：**

```
[開始ノード]
  ↓ ユーザーの質問
  ↓
[LLM Memory：直近5ターンの会話を自動保持]
  ↓
[知識検索ノード1：製品マニュアル]
  クエリ：{{#start.question#}}
  ↓
[知識検索ノード2：過去の問い合わせ履歴]
  クエリ：{{#start.question#}}
  ↓
[LLMノード：回答生成]
  プロンプト：
  「以下の情報を使って回答してください：

   【直近の会話文脈】
   （Memoryが自動で提供）

   【製品マニュアル】
   {{#知識検索1.result#}}

   【過去の問い合わせ】
   {{#知識検索2.result#}}

   【質問】
   {{#start.question#}}」
  ↓
[終了ノード]
```

**実装のポイント：**

- Memory機能は自動的に直近の会話を保持
- RAGで静的な情報（マニュアル）と動的な情報（過去の履歴）を検索
- LLMが両方の情報を統合して回答

**メリット：**

- ✅ 直近の文脈を自然に理解
- ✅ 過去の情報も正確に検索
- ✅ 設定が比較的簡単

**デメリット：**

- ❌ 会話が長くなるとMemoryのコストが増加
- ❌ 重要な情報が古くなるとMemoryから消える

#### パターン2: 会話変数 + RAG

**ユースケース：パーソナライズされた学習アシスタント**

```
【初回訪問】
ユーザー「Pythonを学びたい」
  ↓
ボット「お名前を教えてください」
ユーザー「田中太郎です」
  ↓ 会話変数に保存：user_name = "田中太郎"
  ↓ 会話変数に保存：learning_topic = "Python"
  ↓ 会話変数に保存：learning_level = "初級"

【2回目訪問】
ユーザー「今日は何を学ぶべき？」
  ↓ 会話変数を参照：user_name, learning_topic, learning_level
  ↓ RAG検索：「Python 初級 次のステップ」
  ↓
ボット「田中さん、Pythonの基礎は完了しましたので、
      次は関数について学びましょう」

【3回目訪問】
ユーザー「関数の練習問題を出して」
  ↓ 会話変数を更新：learning_topic = "Python関数"
  ↓ RAG検索：「Python 関数 練習問題」
  ↓
ボット「田中さん向けの練習問題です...」
```

**ワークフロー図：**

```
[開始ノード]
  ↓
[条件分岐：初回訪問チェック]
  ├─ {{#conversation.user_name#}}が空
  │   ↓
  │ [LLMノード：ユーザー情報収集]
  │   「お名前と学習したいトピックを教えてください」
  │   ↓ 構造化出力
  │ [Variable Assigner]
  │   user_name = {{#LLM.name#}}
  │   learning_topic = {{#LLM.topic#}}
  │   learning_level = "初級"
  │
  └─ {{#conversation.user_name#}}が存在
      ↓
[知識検索：学習教材]
  クエリ：「{{#conversation.learning_topic#}}
          {{#conversation.learning_level#}}」
  ↓
[LLMノード：回答生成]
  プロンプト：
  「{{#conversation.user_name#}}さんへ：

   現在の学習状況：
   - トピック：{{#conversation.learning_topic#}}
   - レベル：{{#conversation.learning_level#}}

   【学習教材】
   {{#知識検索.result#}}

   上記を踏まえて、パーソナライズされた学習内容を提案してください」
  ↓
[Variable Assigner：進捗更新]
  learning_progress = "{{#LLMノード.output#}}"
  ↓
[終了ノード]
```

**保存する会話変数の例：**

| 変数名 | 説明 | 例 |
|--------|------|-----|
| `user_name` | ユーザー名 | "田中太郎" |
| `learning_topic` | 学習トピック | "Python" |
| `learning_level` | 学習レベル | "初級" |
| `completed_lessons` | 完了したレッスン | ["基礎", "変数", "条件分岐"] |
| `last_lesson_date` | 最終学習日 | "2024-12-10" |

**メリット：**

- ✅ トークン消費が少ない（必要な情報のみ保持）
- ✅ パーソナライズされた体験
- ✅ 長期間の情報保持が可能

**デメリット：**

- ❌ 実装がやや複雑
- ❌ どの情報を保存するか設計が必要

#### パターン3: 会話要約のRAG保存

**ユースケース：長期的な顧客関係管理**

```
【会話終了時】
長い会話（50ターン）
  ↓
[LLMノード：会話要約]
  「この会話を要約してください」
  ↓
要約：「顧客ABC社の田中様。Proプランへのアップグレードを検討中。
      主な懸念は価格とサポート体制。次回フォローアップ予定」
  ↓
[RAGに保存]
  タイトル：「2024-12-10 ABC社 田中様との会話」
  内容：要約テキスト
  メタデータ：{customer: "ABC社", date: "2024-12-10", topic: "アップグレード"}

【次回訪問時（1週間後）】
ユーザー「先週相談した件ですが...」
  ↓
[RAG検索：過去の会話要約]
  クエリ：「ABC社 田中 先週」
  ↓
ボット「先週ご相談いただいたProプランへのアップグレードの件ですね。
      価格とサポート体制についてご説明いたします...」
```

**ワークフロー図：**

```
【会話中のワークフロー】
[開始ノード]
  ↓
[RAG検索：過去の会話要約]
  クエリ：{{#start.user_id#}} + 最近の会話
  ↓
[LLMノード：回答生成 + 会話]
  過去の要約を踏まえた対応
  ↓
[Variable Assigner：会話ログ蓄積]
  conversation_log += {{#LLMノード.output#}}
  ↓
[終了ノード]

【会話終了時のワークフロー（トリガー：セッション終了）】
[開始]
  ↓
[LLMノード：会話要約]
  プロンプト：
  「以下の会話を要約してください：

   {{#conversation.conversation_log#}}

   【要約形式】
   - 顧客名
   - 主な相談内容
   - 決定事項
   - 次のアクション
   - 重要なキーワード」
  ↓
[HTTPリクエスト：ナレッジベースに保存]
  POST /knowledge-base/documents
  {
    "title": "{{#date#}} {{#user_name#}}との会話",
    "content": {{#LLMノード.要約#}},
    "metadata": {
      "user_id": "{{#user_id#}}",
      "date": "{{#date#}}",
      "topics": {{#LLMノード.キーワード#}}
    }
  }
  ↓
[終了]
```

**メリット：**

- ✅ 長い会話でもトークン消費を抑制
- ✅ 長期的な顧客履歴の管理
- ✅ 検索可能な形で保存

**デメリット：**

- ❌ 要約時に情報の損失がある
- ❌ 実装が最も複雑

---

### 実践例

#### 例1: 会話履歴を活用した製品サポートボット

**シナリオ：** ユーザーが過去の問い合わせを参照しながら製品サポートを受ける

**使用するサンプルデータ：**
- `product-manual.md` - 製品マニュアル（RAG）
- `faq-customer-support.md` - FAQ（RAG）
- 会話変数でユーザー情報を管理

**ワークフロー構成：**

```
[開始ノード]
  ↓ 入力：question（ユーザーの質問）
  ↓
[条件分岐：初回訪問チェック]
  ├─ {{#conversation.customer_id#}}が空
  │   ↓
  │ [LLMノード：顧客情報収集]
  │   「お客様のIDまたは名前を教えてください」
  │   ↓
  │ [Variable Assigner]
  │   customer_id = {{#LLMノード.id#}}
  │   customer_name = {{#LLMノード.name#}}
  │   inquiry_count = 0
  │
  └─ {{#conversation.customer_id#}}が存在
      ↓
[知識検索1：製品マニュアル]
  ナレッジベース：product-manual
  クエリ：{{#start.question#}}
  Top K: 3
  スコア閾値: 0.7
  ↓
[知識検索2：FAQ]
  ナレッジベース：faq-customer-support
  クエリ：{{#start.question#}}
  Top K: 2
  スコア閾値: 0.7
  ↓
[LLMノード：回答生成]
  プロンプト：
  「{{#conversation.customer_name#}}様へ

   【今回のご質問】
   {{#start.question#}}

   【製品マニュアルより】
   {{#知識検索1.result#}}

   【FAQより】
   {{#知識検索2.result#}}

   【回答ルール】
   - 顧客名で呼びかける
   - マニュアルとFAQの情報を統合
   - 具体的な手順を提示
   - 追加質問を促す

   以前{{#conversation.inquiry_count#}}回お問い合わせいただいている場合は、
   「いつもご利用ありがとうございます」と伝える」
  ↓
[Variable Assigner：問い合わせ回数更新]
  inquiry_count = {{#conversation.inquiry_count#}} + 1
  ↓
[終了ノード]
```

**テスト例：**

```
【初回訪問】
ユーザー「FlowMasterのセットアップ方法は？」
  ↓
ボット「お客様のIDまたは名前を教えてください」
ユーザー「田中太郎です」
  ↓ customer_name = "田中太郎", inquiry_count = 0
ボット「田中太郎様、FlowMasterのセットアップ方法ですね。
      以下の手順で設定できます：
      1. ...
      2. ...」
  ↓ inquiry_count = 1

【2回目（同じセッション内）】
ユーザー「パスワードを忘れた場合は？」
  ↓ customer_name = "田中太郎", inquiry_count = 1
ボット「田中太郎様、いつもご利用ありがとうございます。
      パスワードのリセット方法は...」
  ↓ inquiry_count = 2

【繰り返しの質問】
ユーザー「さっき聞いたセットアップ、もう一度教えて」
  ↓ Memory機能が直近の会話を覚えている
ボット「先ほどご案内したFlowMasterのセットアップ手順ですね。
      改めてご説明いたします：
      1. ...」
```

#### 例2: 学習アシスタント（長期記憶型）

**シナリオ：** ユーザーの学習進捗を管理しながら、適切な教材を提供

**使用するサンプルデータ：**
- `meeting-notes-01.md`, `meeting-notes-02.md` - 学習教材として活用（RAG）
- 会話変数で学習進捗を管理

**保存する会話変数：**

| 変数名 | 型 | 説明 | 例 |
|--------|-----|------|-----|
| `learner_name` | 文字列 | 学習者名 | "鈴木花子" |
| `current_topic` | 文字列 | 現在の学習トピック | "プロジェクト管理" |
| `completed_topics` | 配列 | 完了したトピック | ["基礎", "要件定義"] |
| `learning_goal` | 文字列 | 学習目標 | "PMになる" |
| `next_review_date` | 日付 | 次回復習日 | "2024-12-15" |

**ワークフロー構成：**

```
[開始ノード]
  ↓
[条件分岐：初回訪問]
  ├─ {{#conversation.learner_name#}}が空
  │   ↓
  │ [LLMノード：プロフィール収集]
  │   「お名前と学習目標を教えてください」
  │   ↓ 構造化出力
  │ [Variable Assigner]
  │   learner_name = {{#LLM.name#}}
  │   learning_goal = {{#LLM.goal#}}
  │   completed_topics = []
  │   current_topic = "基礎"
  │
  └─ {{#conversation.learner_name#}}が存在
      ↓
[LLMノード：質問分析]
  プロンプト：
  「以下の質問を分析してください：
   {{#start.question#}}

   1. 新しいトピックを学びたい
   2. 現在のトピックの復習
   3. 練習問題を解きたい

   どれに該当しますか？」
  ↓ 構造化出力：{"type": "新規学習"}
  ↓
[条件分岐：質問タイプ]
  ├─ type="新規学習"
  │   ↓
  │ [知識検索：学習教材]
  │   クエリ：「{{#conversation.current_topic#}} 次のステップ」
  │   ↓
  │ [LLMノード：新規学習内容]
  │   ↓
  │ [Variable Assigner：進捗更新]
  │   completed_topics += {{#conversation.current_topic#}}
  │   current_topic = {{#LLMノード.next_topic#}}
  │
  ├─ type="復習"
  │   ↓
  │ [知識検索：学習教材]
  │   クエリ：「{{#conversation.completed_topics#}} 復習」
  │   ↓
  │ [LLMノード：復習問題生成]
  │
  └─ type="練習問題"
      ↓
    [知識検索：学習教材]
      クエリ：「{{#conversation.current_topic#}} 練習問題」
      ↓
    [LLMノード：練習問題出題]
  ↓
[終了ノード]
```

**テスト例：**

```
【Day 1: 初回訪問】
ユーザー「プロジェクト管理を学びたい」
ボット「お名前と学習目標を教えてください」
ユーザー「鈴木花子です。PMになりたいです」
  ↓ 変数保存
ボット「鈴木花子さん、PMを目指すのですね！
      まずは基礎から始めましょう。
      プロジェクト管理の基本概念について学習します...」
  ↓ current_topic = "基礎"

【Day 2: 2回目訪問】
ユーザー「今日は何を学ぶべき？」
  ↓ 変数参照：learner_name, current_topic, completed_topics
  ↓ RAG検索：「基礎 次のステップ」
ボット「鈴木花子さん、基礎は完了しましたので、
      次は要件定義について学びましょう...」
  ↓ completed_topics = ["基礎"]
  ↓ current_topic = "要件定義"

【Day 7: 復習】
ユーザー「先週学んだことを復習したい」
  ↓ 変数参照：completed_topics = ["基礎", "要件定義", "設計"]
  ↓ RAG検索：「基礎 要件定義 設計 復習」
ボット「鈴木花子さん、これまで学んだ内容の復習ですね。
      復習問題を出します：
      Q1: プロジェクトの3つの制約とは？
      Q2: 要件定義フェーズで最も重要なことは？
      ...」
```

---

### ベストプラクティス

#### トークン消費の最適化

**✅ 必要な情報だけをコンテキストに含める**

```
【❌ 悪い例】
すべての会話履歴をLLMに渡す
  ↓
50ターンの会話 = 15,000トークン = ¥45/リクエスト

【✅ 良い例】
会話変数で重要な情報のみ保持
  ↓
変数：user_name, plan, inquiry_count = 100トークン = ¥0.3/リクエスト
```

**✅ 会話変数の効率的な使用**

| 保存する情報 | Memory使用時 | 会話変数使用時 |
|------------|------------|-------------|
| ユーザー名 | 全会話履歴（数千トークン） | 変数のみ（10トークン） |
| 選択したプラン | 全会話履歴 | 変数のみ（5トークン） |
| 過去の質問 | 全会話履歴 | RAGに保存（0トークン） |

**✅ RAGとMemoryの使い分け**

```
【短期情報（直近5ターン）】
→ Memory または 会話変数

【長期情報（1週間前の会話）】
→ RAG（会話要約を保存）

【静的情報（製品マニュアル）】
→ RAG
```

#### メモリの効率的な使用

**いつMemoryを使うか：**

- ✅ 会話が10ターン以内
- ✅ 文脈の自然な理解が最優先
- ✅ コストよりUXを重視

**いつ会話変数を使うか：**

- ✅ 会話が20ターン以上
- ✅ 構造化された情報を管理
- ✅ コストを抑えたい

**ハイブリッドアプローチ：**

```
Memory（直近3-5ターン）+ 会話変数（重要情報）+ RAG（過去の履歴）
  ↓
最高のUX + 低コスト + 長期記憶
```

#### エラーハンドリング

**会話変数が空の場合の処理：**

```
[LLMノード]
  プロンプト：
  「{% if conversation.user_name %}
     {{conversation.user_name}}様
   {% else %}
     お客様
   {% endif %}

   へのご案内です...」
```

**RAG検索結果がない場合の処理：**

```
[条件分岐]
  ├─ {{#知識検索.result#}}が空
  │   ↓
  │ [LLMノード]
  │   「申し訳ございません。その情報は見つかりませんでした。
  │    別の質問をしていただけますか？」
  │
  └─ {{#知識検索.result#}}が存在
      ↓
    [LLMノード：通常の回答]
```

---

### まとめ

#### 会話履歴とRAGの統合で実現できること

```
【従来のRAGのみ】
ユーザー「製品Aの価格は？」
ボット（RAG）「製品Aは1,200円です」
ユーザー「その製品の在庫は？」
ボット「どの製品でしょうか？」
  ↓
文脈が失われる

【Memory + RAG】
ユーザー「製品Aの価格は？」
ボット（RAG）「製品Aは1,200円です」
  ↓ Memory: "製品A"を記憶
ユーザー「その製品の在庫は？」
ボット（Memory + RAG）「製品Aの在庫は15個です」
  ↓
自然な会話 + 正確な情報

【会話変数 + RAG】
ユーザー「製品Aを検討中」
  ↓ 変数: interested_product = "製品A"
（10ターン後）
ユーザー「在庫ありますか？」
ボット（変数 + RAG）「検討中の製品Aですね。在庫は15個です」
  ↓
長期的な文脈保持 + 低コスト
```

#### 3つの管理方法の使い分け

| シナリオ | 推奨方法 | 理由 |
|---------|---------|------|
| **簡単なFAQボット（5-10ターン）** | LLM Memory | シンプル、自然な会話 |
| **カスタマーサポート（20ターン以上）** | 会話変数 + RAG | コスト効率、パーソナライズ |
| **学習アシスタント（長期利用）** | 会話変数 + RAG（要約保存） | 長期記憶、進捗管理 |
| **外部アプリ統合** | conversation_id + RAG | セッション管理、API連携 |

#### 推奨アプローチ

**ステップ1: 要件を整理**
- 会話の長さは？（短い or 長い）
- 何を記憶すべき？（すべて or 一部）
- コスト制約は？（高 or 低）

**ステップ2: 方法を選択**
```
短い会話（5-10ターン） → LLM Memory
長い会話（20ターン以上） → 会話変数
超長期（数ヶ月） → RAG要約保存
```

**ステップ3: RAGと組み合わせ**
```
会話履歴（短期） + RAG（長期） = 完璧な記憶システム
```

---

### 参考リンク

**Dify公式ドキュメント：**
- [Chatflow - 対話履歴記憶機能](https://docs.dify.ai/ja-jp/guides/workflow/chatflow)

**Web検索から取得した情報：**
- [Dify v0.7.0: 会話変数の導入](https://dify.ai/blog/enhancing-llm-memory-with-conversation-variables-and-variable-assigners)
- [DifyのAPI経由のチャットボットでもメモリー機能を使う方法](https://note.com/oft0nland/n/n0dd4333ea673)
- [Difyの使い方（メモリ―機能と会話変数とは）](https://gaaaon.jp/blog/dify-memory-function)
- [【Dify】会話変数を用いた自然な会話を実現するチャットボット](https://zenn.dev/upgradetech/articles/2989d586ef1f0f)

**Context7から取得した情報：**
- Chat API - conversation_id によるセッション管理
- Agent Strategy Plugin - history-messages 機能
- Chatflow - 対話履歴記憶とコンテキスト管理

---

## 7. マーケットプレイスの組み込みツール

### なぜツールが必要なのか？

ナレッジベース（RAG）は強力ですが、**すべての情報ニーズに対応できるわけではありません**。

**RAGでは対応できないケース：**

```
ユーザー「最新のCOVID-19ワクチンに関する論文を教えてください」
  ↓
RAG検索「ナレッジベースから検索...」
  ↓
「関連する情報が見つかりません」
  ↓
（ナレッジベースに登録されていない最新情報は取得できない！）
```

**組み込みツール（ArXiv）なら：**

```
ユーザー「最新のCOVID-19ワクチンに関する論文を教えてください」
  ↓
ArXivツール「COVID-19 vaccine で論文を検索...」
  ↓
「2025年の最新論文が見つかりました：〇〇〇...」
  ↓
（最新の外部情報をリアルタイムで取得できる！）
```

### ナレッジベースとツールの違い

| 項目 | ナレッジベース（RAG） | 組み込みツール |
|------|---------------------|--------------|
| **用途** | 静的な文書検索 | 外部情報の検索・取得 |
| **データソース** | 事前登録された文書 | Wikipedia、学術論文DB、Web検索 |
| **更新頻度** | 手動更新 | 常に最新 |
| **得意なこと** | 社内マニュアル、FAQ、規定文書 | 百科事典、最新論文、ニュース |
| **セットアップ** | 文書をアップロード | マーケットプレイスからインストール |

### マーケットプレイスとは

**Dify Marketplace**は、様々な組み込みツールやプラグインを提供するプラットフォームです。

#### マーケットプレイスの特徴

- **簡単導入**: ワンクリックでツールをインストール
- **豊富な種類**: 検索、翻訳、画像生成など多様なツール
- **即使用可能**: 複雑な設定不要で、すぐにワークフローに追加できる

#### 組み込みツール vs カスタムツール

| 項目 | 組み込みツール | カスタムツール |
|------|--------------|--------------|
| **設定方法** | マーケットプレイスからインストール | OpenAPI形式で自分で定義 |
| **対象** | 一般的な外部サービス（Wikipedia、ArXivなど） | 自社API、独自サービス |
| **セットアップ** | 簡単（APIキーのみ） | 複雑（API仕様の記述が必要） |
| **メリット** | すぐに使える | 柔軟なカスタマイズ可能 |

### 主な組み込みツール

#### 1. Wikipedia（ウィキペディア）

**概要：** 無料の百科事典検索ツール

**用途：**
- 一般的な用語の説明
- 歴史的な出来事の情報
- 有名人物や企業の基本情報

**特徴：**
- ✅ APIキー不要（無料）
- ✅ 多言語対応（日本語、英語など）
- ✅ 膨大な知識ベース

**使用例：**

```
ユーザー「量子コンピュータとは何ですか？」
  ↓
[Wikipedia検索ノード]
  ↓ クエリ: "量子コンピュータ"
  ↓ 結果: Wikipediaから要約を取得
[LLMノード]
  ↓ わかりやすく説明
ユーザーへの回答: 「量子コンピュータは、量子力学の原理を利用して...」
```

#### 2. ArXiv（アーカイブ）

**概要：** 学術論文の検索・取得ツール

**用途：**
- 最新の研究論文の検索
- 特定分野の学術情報
- 論文の要約・引用情報

**特徴：**
- ✅ 最新の研究情報にアクセス
- ✅ 物理学、数学、CS、生物学など幅広い分野
- ✅ 無料で利用可能

**使用例：**

```
ユーザー「機械学習の最新研究を教えてください」
  ↓
[ArXiv検索ノード]
  ↓ クエリ: "machine learning"
  ↓ 結果: 最新の論文リストを取得
[LLMノード]
  ↓ 論文の要約を生成
ユーザーへの回答: 「2025年の最新論文によると...」
```

#### 3. DuckDuckGo（ダックダックゴー）

**概要：** プライバシー重視のWeb検索エンジン

**用途：**
- リアルタイムのニュース検索
- 最新情報の取得
- 一般的なWeb検索

**特徴：**
- ✅ プライバシー保護（トラッキングなし）
- ✅ 最新情報にアクセス
- ✅ APIキー不要

**使用例：**

```
ユーザー「東京の今日の天気は？」
  ↓
[DuckDuckGo検索ノード]
  ↓ クエリ: "東京 天気 今日"
  ↓ 結果: 最新の天気情報を取得
[LLMノード]
  ↓ わかりやすく整形
ユーザーへの回答: 「東京は晴れ、気温は15℃です」
```

### 3つのツールの使い分け

| ツール | 適したケース | 不適切なケース |
|--------|------------|--------------|
| **Wikipedia** | 一般知識、用語解説、歴史 | リアルタイム情報、最新ニュース |
| **ArXiv** | 学術論文、最新研究、専門知識 | 一般的な質問、ビジネス情報 |
| **DuckDuckGo** | 最新ニュース、現在の情報 | 詳細な専門知識、歴史的事実 |

### ツールの追加と設定

#### ステップ1: マーケットプレイスを開く

1. Difyにログイン
2. 左メニューから「ツール」をクリック
3. 「マーケットプレイス」タブを選択

#### ステップ2: ツールをインストール

1. 使いたいツール（例：Wikipedia）を検索
2. ツールカードをクリック
3. 「インストール」ボタンをクリック

#### ステップ3: 認証設定（必要な場合）

**Wikipedia の場合：**
- ❌ APIキー不要（そのまま使用可能）

**ArXiv の場合：**
- ❌ APIキー不要（そのまま使用可能）

**DuckDuckGo の場合：**
- ❌ APIキー不要（そのまま使用可能）

※一部の高度なツールではAPIキーが必要な場合があります。

### ワークフローでの使用

#### 基本的な使用方法

**例：Wikipedia検索ボット**

```
[開始ノード]
  ↓ 入力変数：query（検索したい用語）
[ツールノード：Wikipedia検索]
  ↓ パラメータ：query = {{#start.query#}}
  ↓ 言語：ja（日本語）
[LLMノード]
  ↓ 検索結果をわかりやすく説明
[終了ノード]
```

#### ツールノードの設定

| パラメータ | 説明 | 例 |
|----------|------|----|
| **ツール** | 使用するツール | Wikipedia |
| **クエリ** | 検索キーワード | {{#start.query#}} |
| **言語** | 検索言語（Wikipediaの場合） | ja, en |
| **結果数** | 取得する結果の数 | 1-5 |

#### LLMノードでの結果活用

**プロンプト例：**

```
以下はWikipediaから取得した情報です。
この情報をもとに、ユーザーにわかりやすく説明してください。

【Wikipedia検索結果】
{{#Wikipedia検索.result#}}

【回答ルール】
- 専門用語は簡単な言葉で説明する
- 具体例を交えて説明する
- 長すぎる場合は要約する

【回答】
```

### ワークフロー実装例

#### 例1: 用語解説ボット（Wikipedia）

**シナリオ：** ユーザーが質問した用語をWikipediaで検索し、わかりやすく説明

**ワークフロー：**

```
[開始ノード]
  ↓ 入力：user_question（例：「ブロックチェーンとは？」）
[LLMノード1：用語抽出]
  ↓ 構造化出力でキーワードを抽出
[ツールノード：Wikipedia検索]
  ↓ クエリ：抽出したキーワード
[LLMノード2：説明生成]
  ↓
[終了ノード]
```

**LLMノード1のプロンプト（用語抽出）：**

```
ユーザーの質問から、検索すべきキーワードを抽出してください。

【質問】
{{#start.user_question#}}

【抽出ルール】
- 主要な名詞やキーワードを抽出
- 複数ある場合は最も重要なものを選ぶ

JSON形式で出力してください。
```

**JSON Schema：**
```json
{
  "type": "object",
  "properties": {
    "keyword": {
      "type": "string",
      "description": "検索キーワード"
    }
  },
  "required": ["keyword"]
}
```

**LLMノード2のプロンプト（説明生成）：**

```
以下のWikipedia情報をもとに、初心者にもわかりやすく説明してください。

【Wikipedia検索結果】
{{#Wikipedia検索.result#}}

【回答ルール】
- 小学生でも理解できる言葉で説明
- 専門用語には補足説明を添える
- 身近な例えを使う
- 3-5文程度で簡潔に

【回答】
```

#### 例2: 論文検索アシスタント（ArXiv）

**シナリオ：** 特定のテーマに関する最新の学術論文を検索・要約

**ワークフロー：**

```
[開始ノード]
  ↓ 入力：research_topic（研究テーマ）
[ツールノード：ArXiv検索]
  ↓ クエリ：{{#start.research_topic#}}
  ↓ 結果数：5
[LLMノード：論文要約]
  ↓
[終了ノード]
```

**LLMノードのプロンプト（論文要約）：**

```
以下の論文検索結果から、重要なポイントを要約してください。

【ArXiv検索結果】
{{#ArXiv検索.result#}}

【要約ルール】
- 各論文のタイトルと著者を明記
- 主な内容を1-2文で要約
- 発行年を示す
- 最大3つの論文を紹介

【要約形式】
1. [論文タイトル]（著者名、発行年）
   要約：〇〇〇〇

2. [論文タイトル]（著者名、発行年）
   要約：〇〇〇〇
```

#### 例3: 最新ニュース検索（DuckDuckGo）

**シナリオ：** 指定したトピックに関する最新ニュースを検索

**ワークフロー：**

```
[開始ノード]
  ↓ 入力：news_topic（ニューストピック）
[ツールノード：DuckDuckGo検索]
  ↓ クエリ：{{#start.news_topic#}} + " ニュース"
[LLMノード：ニュース整理]
  ↓
[終了ノード]
```

**LLMノードのプロンプト（ニュース整理）：**

```
以下の検索結果から、最新のニュースをまとめてください。

【DuckDuckGo検索結果】
{{#DuckDuckGo検索.result#}}

【整理ルール】
- 最新の情報を優先
- 信頼できる情報源かを確認
- 箇条書きで整理
- 日付を明記

【回答形式】
〇〇に関する最新ニュース：

- [日付] [見出し]
  概要：〇〇〇

- [日付] [見出し]
  概要：〇〇〇
```

### RAGとツールの組み合わせ

#### パターン1: 社内情報はRAG、外部情報はツール

**シナリオ：** 製品サポートボット

```
[開始ノード]
  ↓ 入力：user_question
[LLMノード：質問分類]
  ↓ 構造化出力で分類
[条件分岐]
  ├─ 「製品の使い方」→ [知識検索：製品マニュアル]（RAG）
  ├─ 「業界動向」→ [DuckDuckGo検索]（ツール）
  └─ 「関連論文」→ [ArXiv検索]（ツール）
  ↓
[LLMノード：回答生成]
  ↓
[終了ノード]
```

#### パターン2: RAGの補完としてツールを使用

**シナリオ：** RAGで見つからない場合、外部検索で補完

```
[開始ノード]
  ↓
[知識検索ノード]（RAG）
  ↓
[条件分岐：スコアチェック]
  ├─ スコア ≥ 0.7 → [LLMノード：RAG結果で回答]
  └─ スコア < 0.7 → [Wikipedia検索] → [LLMノード：Wikipedia結果で回答]
  ↓
[終了ノード]
```

### RAGとツールの使い分け

| ユースケース | RAG | Wikipedia | ArXiv | DuckDuckGo |
|------------|-----|-----------|-------|------------|
| **社内マニュアル** | ✅ | - | - | - |
| **用語解説** | △ | ✅ | - | - |
| **最新ニュース** | - | - | - | ✅ |
| **学術論文** | △ | - | ✅ | - |
| **一般知識** | △ | ✅ | - | △ |
| **会社独自の情報** | ✅ | - | - | - |

**選択基準：**
- **自社情報・機密情報** → RAG
- **一般知識・用語** → Wikipedia
- **学術情報・最新研究** → ArXiv
- **最新ニュース・トレンド** → DuckDuckGo

### 演習4: Wikipedia検索ボットの作成

**目標：** Wikipediaツールを使って、用語を検索・説明するボットを作成

#### 手順

**1. ツールのインストール**

1. Difyの「ツール」→「マーケットプレイス」を開く
2. 「Wikipedia」を検索
3. 「インストール」をクリック

**2. ワークフローの構築**

```
[開始ノード]
  ↓ 入力変数：term（検索したい用語）
[ツールノード：Wikipedia検索]
  ↓ パラメータ：
     - query: {{#start.term#}}
     - language: ja
[LLMノード：説明生成]
  ↓
[終了ノード]
```

**3. ツールノードの設定**

| パラメータ | 値 |
|----------|---|
| ツール | Wikipedia |
| query | {{#start.term#}} |
| language | ja |

**4. LLMノードのプロンプト**

```
以下はWikipediaから取得した「{{#start.term#}}」の情報です。
この情報をもとに、初心者にもわかりやすく説明してください。

【Wikipedia情報】
{{#Wikipedia検索.result#}}

【回答ルール】
- 3-5文程度で簡潔に説明
- 専門用語には補足を添える
- 具体例を1つ挙げる

【回答】
```

**5. テスト実行**

入力例：
- 「人工知能」
- 「ブロックチェーン」
- 「量子コンピュータ」

**期待される出力：**
```
人工知能（AI）とは、人間の知能を模倣したコンピュータシステムのことです。
機械学習や深層学習などの技術を使って、データからパターンを学習し、
予測や判断を行います。例えば、音声認識や画像認識、自動運転などに
応用されています。
```

### 演習5: 複合検索ボット（RAG + ツール）

**目標：** RAGと組み込みツールを組み合わせた高度な検索ボット

#### シナリオ

ユーザーの質問に対し：
- **社内製品情報** → RAG（製品マニュアル）
- **一般的な用語** → Wikipedia
- **最新ニュース** → DuckDuckGo

#### ワークフロー構成

```
[開始ノード]
  ↓ 入力：user_question
[LLMノード1：質問分類]（構造化出力）
  ↓
[条件分岐ノード]
  ├─ category="製品情報" → [知識検索：製品マニュアル]（RAG）
  ├─ category="用語解説" → [Wikipedia検索]
  └─ category="最新情報" → [DuckDuckGo検索]
  ↓
[LLMノード2：回答生成]
  ↓
[終了ノード]
```

#### LLMノード1（質問分類）

**JSON Schema：**
```json
{
  "type": "object",
  "properties": {
    "category": {
      "type": "string",
      "description": "質問のカテゴリ",
      "enum": ["製品情報", "用語解説", "最新情報"]
    },
    "query": {
      "type": "string",
      "description": "検索クエリ"
    }
  },
  "required": ["category", "query"]
}
```

**プロンプト：**
```
ユーザーの質問を分析し、適切なカテゴリに分類してください。

【質問】
{{#start.user_question#}}

【カテゴリ】
- 製品情報：当社の製品やサービスに関する質問
- 用語解説：一般的な用語や概念の説明
- 最新情報：ニュースや最近の出来事

【検索クエリ】
質問から適切な検索キーワードを抽出してください。
```

#### テスト入力例

**ケース1：製品情報**
```
「FlowMasterの料金プランを教えてください」
→ category: "製品情報"
→ query: "料金プラン"
→ 知識検索ノード（RAG）が実行される
```

**ケース2：用語解説**
```
「アジャイル開発とは何ですか？」
→ category: "用語解説"
→ query: "アジャイル開発"
→ Wikipedia検索ノードが実行される
```

**ケース3：最新情報**
```
「生成AIの最新動向を教えてください」
→ category: "最新情報"
→ query: "生成AI 最新動向"
→ DuckDuckGo検索ノードが実行される
```

### ベストプラクティス

#### 1. 適切なツール選択

```
質問の性質を見極める
  ↓
├─ 社内情報 → RAG
├─ 百科事典的知識 → Wikipedia
├─ 学術情報 → ArXiv
└─ 最新ニュース → DuckDuckGo
```

#### 2. フォールバック戦略

```
[第1選択：RAG]
  ↓ スコア低い
[第2選択：Wikipedia]
  ↓ 見つからない
[第3選択：DuckDuckGo]
```

#### 3. 結果の検証

- ✅ 情報源を明記する
- ✅ 検索結果のスコアをチェック
- ✅ 見つからない場合の代替案を用意

---

## よくある質問（FAQ）

### Q1: チャンクサイズはどう決めればいいですか？

**A:** 以下の基準で判断しましょう：

**小さい（100-300トークン）：**
- FAQ形式
- 短い段落中心の文書
- キーワード検索が中心

**中程度（300-600トークン）：**
- 一般的なドキュメント
- マニュアル
- 記事

**大きい（800-1000トークン）：**
- 詳細な技術文書
- 長い説明が必要
- 文脈の連続性が重要

### Q2: Top Kとスコア閾値はどう設定すべきですか？

**A:** 以下の組み合わせを試してください：

| ケース | Top K | スコア閾値 |
|--------|-------|-----------|
| **精度重視** | 2-3 | 0.75-0.8 |
| **バランス** | 3-5 | 0.6-0.7 |
| **網羅性重視** | 5-10 | 0.5-0.6 |

### Q3: 検索結果が期待と違う場合は？

**A:** 以下を試してください：

1. **チャンクサイズの調整**
   - 小さくする：より細かく検索
   - 大きくする：より広い文脈を取得

2. **質問の最適化**
   - LLMノードで質問を言い換える
   - キーワードを明確にする

3. **埋め込みモデルの変更**
   - 日本語に強いモデルに変更
   - より高性能なモデルを試す

4. **スコア閾値を下げる**
   - より多くの候補を取得

### Q4: RAGとカスタムツールはどう使い分けるべきですか？

**A:** 以下の基準で判断しましょう：

**RAGを使う場合：**
- ✅ 文書が静的（頻繁に変わらない）
- ✅ テキスト検索が中心
- ✅ 事前に文書を準備できる

**カスタムツールを使う場合：**
- ✅ リアルタイムデータが必要
- ✅ データベースから動的に取得
- ✅ 計算や処理が必要

### Q5: 外部ナレッジベースはいつ使うべきですか？

**A:** 以下のケースで検討してください：

- 既存の検索システムがある
- 独自のベクトルDBを運用している
- 複雑なメタデータフィルタリングが必要
- Difyの制限を超える大規模データ

### Q6: 複数のナレッジベースを同時に検索できますか？

**A:** はい、可能です。以下の方法があります：

**方法1: 複数の知識検索ノードを並列実行**

```
[開始ノード]
  ├→ [知識検索ノード1：製品マニュアル]
  ├→ [知識検索ノード2：FAQ]
  └→ [知識検索ノード3：トラブルシューティング]
  ↓（すべての結果を統合）
[LLMノード]
```

**方法2: 1つのナレッジベースに統合**
- 複数の文書を同じナレッジベースに登録
- メタデータでカテゴリ分け

---

## まとめ

### この回で学んだこと

✅ **ナレッジベースの本質**
- LLMが参照する外部知識の集合
- RAGは情報取得手段の一つ
- 様々な方法で知識にアクセス可能

✅ **RAGの仕組み**
- インデキシング（チャンク化、埋め込み、保存）
- 検索（類似検索、Top K、スコア閾値）
- 生成（LLMによる回答生成）

✅ **Difyでの実装**
- ナレッジベースの作成と管理
- 知識検索ノードの使い方
- チャンク化と埋め込みモデルの設定

✅ **会話履歴とRAGの統合**
- 会話履歴管理の3つの方法（LLM Memory、会話変数、conversation_id）
- RAGと会話履歴の組み合わせパターン
- 長期記憶と短期記憶の使い分け

✅ **マーケットプレイスの組み込みツール**
- Wikipedia、ArXiv、DuckDuckGoの活用
- ツールのインストールと設定
- RAGとツールの使い分け

✅ **応用的な活用**
- 外部ナレッジベースとの連携
- 会話履歴とRAGの複合的な活用
- 複数のツールを組み合わせたワークフロー

### 次のステップ

次回は、さらに高度な機能を学びます：

- **第4回：エージェントとツール連携**
  - AIエージェントの設計と実装
  - 複数のツールを組み合わせた複雑なワークフロー
  - 自律的なタスク実行

### 練習課題

以下のアプリケーションを自分で作ってみましょう：

#### RAG基礎編

1. **レシピ検索ボット**
   - 材料名から関連レシピを検索
   - 複数のレシピを比較

2. **技術文書Q&Aシステム**
   - 技術マニュアルを複数登録
   - 引用元を明示した回答

3. **社内ヘルプデスク**
   - 就業規則、経費規則などの複数文書
   - カテゴリ自動分類と適切な文書からの検索

#### カスタムツール活用編

4. **天気予報アシスタント**
   - 都市名を入力すると天気情報を取得
   - 服装のアドバイスを追加

5. **為替レート計算ボット**
   - 通貨ペアと金額を入力
   - リアルタイムレートで換算

6. **ニュース要約ボット**
   - ニュースAPIから最新記事を取得
   - LLMで要約して表示

#### 統合システム編

7. **顧客サポート統合ボット**
   - 製品の使い方 → RAGで検索
   - 注文状況 → カスタムツールで照会
   - 在庫確認 → カスタムツールで照会
   - 問い合わせ内容を自動分類

8. **社内ポータルアシスタント**
   - 社内規定 → RAGで検索
   - 勤怠情報 → カスタムツールで取得
   - 会議室予約 → カスタムツールでアクション

#### 会話履歴とRAG統合編

9. **会話履歴を活用した製品サポートボット**
   - **目的**: ユーザーの過去の問い合わせを記憶し、文脈を保持した対話を実現
   - **実装要素**:
     - 会話変数でユーザーの前回の質問と回答を保存
     - 製品マニュアル（`product-manual.md`）をRAGで検索
     - 「前回お答えした通り...」のような継続的な対話
   - **サンプルデータ**: `assets/dummy-data/product-manual.md`
   - **ワークフロー構成**:
     ```
     [開始] → [会話変数読み込み] → [RAG検索] → [LLM回答生成] → [会話変数更新]
     ```
   - **会話変数**:
     - `last_question`: 前回の質問
     - `last_answer`: 前回の回答
     - `user_product`: ユーザーが使用している製品名
   - **期待される動作**:
     - 初回: 「FlowMasterの料金プランを教えてください」→ RAGから回答
     - 2回目: 「それは年払いですか？」→ 「前回お答えしたFlowMasterの料金プランについてですね。はい、年払いのオプションもあります」

10. **学習アシスタント（長期記憶型）**
    - **目的**: 学習進捗を記憶し、個別化された学習サポートを提供
    - **実装要素**:
      - 会話変数で学習済みトピック、理解度を管理
      - FAQ（`faq-customer-support.md`）や会社ニュース（`company-news-2024.md`）をRAGで検索
      - 過去の学習履歴を踏まえた復習問題の提示
    - **サンプルデータ**:
      - `assets/dummy-data/faq-customer-support.md`
      - `assets/dummy-data/company-news-2024.md`
    - **ワークフロー構成**:
      ```
      [開始] → [学習履歴確認] → [RAG検索: 関連資料] → [理解度テスト] → [履歴更新]
      ```
    - **会話変数**:
      - `learned_topics`: 学習済みトピックのリスト（JSON配列）
      - `current_topic`: 現在学習中のトピック
      - `understanding_level`: 理解度（初級/中級/上級）
    - **期待される動作**:
      - 初回: 「Difyの基本を教えてください」→ RAGから基礎情報を提供
      - 2回目: 「前回学んだことの復習問題を出してください」→ 学習履歴から復習問題を生成
      - 3回目: 「次のステップを教えてください」→ 理解度に応じた次のトピックを提案

11. **会議議事録検索システム**
    - **目的**: 複数の会議議事録を検索し、直近の会議内容を優先的に提示
    - **実装要素**:
      - 複数の議事録ファイルをRAGに登録
      - 会話変数で直近の会議の要点を保持
      - 「先週の会議で決まったことは？」「プロジェクトの進捗は？」などの質問に対応
    - **サンプルデータ**:
      - `assets/dummy-data/meeting-notes-01.md`（第1回会議）
      - `assets/dummy-data/meeting-notes-02.md`（第2回会議）
    - **ワークフロー構成**:
      ```
      [開始] → [質問分析] → [条件分岐]
                                 ├→ 直近の会議 → [会話変数から取得]
                                 └→ 過去の会議 → [RAG検索]
              → [LLM回答生成]
      ```
    - **会話変数**:
      - `last_meeting_date`: 直近の会議日
      - `last_meeting_summary`: 直近の会議の要約
      - `key_decisions`: 重要な決定事項（JSON配列）
    - **期待される動作**:
      - 「先週の会議で決まったことは？」→ 会話変数から直近の決定事項を回答
      - 「FlowMaster 3.0の開発スケジュールは？」→ RAGで議事録を検索して詳細を回答
      - 「山田さんの担当タスクは？」→ 複数の議事録から該当情報を抽出
    - **高度な機能**:
      - 日付フィルタリング（「12月の会議内容」）
      - 担当者フィルタリング（「鈴木さん関連の議事録」）
      - アクションアイテムの進捗管理

### 参考リンク

- [Dify公式ドキュメント - ナレッジベース](https://docs.dify.ai/guides/knowledge-base)
- [RAG（検索拡張生成）とは](https://docs.dify.ai/resources/termbase)
- [外部ナレッジベースAPI仕様](https://docs.dify.ai/guides/knowledge-base/external-knowledge-api)

---

**お疲れ様でした！** RAGとナレッジベースの理解が深まりましたか？次回はAIエージェントについて学びます。
